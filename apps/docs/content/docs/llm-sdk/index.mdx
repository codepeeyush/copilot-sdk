---
title: LLM SDK
description: Core functions for AI text generation
icon: Sparkles
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';

# LLM SDK

The `@yourgpt/llm-sdk` package provides core functions for working with large language models. Use any provider with a unified, type-safe API.

---

## Quick Example

```ts
import { generateText } from '@yourgpt/llm-sdk';
import { openai } from '@yourgpt/llm-sdk/openai';

const result = await generateText({
  model: openai('gpt-4o'),
  prompt: 'Explain quantum computing in simple terms.',
});

console.log(result.text);
```

---

## Installation

<Tabs items={['pnpm', 'npm', 'yarn']}>
  <Tab value="pnpm">
    ```bash
    pnpm add @yourgpt/llm-sdk zod
    ```
  </Tab>
  <Tab value="npm">
    ```bash
    npm install @yourgpt/llm-sdk zod
    ```
  </Tab>
  <Tab value="yarn">
    ```bash
    yarn add @yourgpt/llm-sdk zod
    ```
  </Tab>
</Tabs>

---

## Core Functions

<Cards>
  <Card title="generateText()" href="/docs/llm-sdk/generate-text">
    Generate text with a single function call. Supports tools and multi-step agentic workflows.
  </Card>
  <Card title="streamText()" href="/docs/llm-sdk/stream-text">
    Stream text responses for real-time output. Perfect for chat interfaces and API routes.
  </Card>
  <Card title="tool()" href="/docs/llm-sdk/tools">
    Define type-safe tools with Zod schemas. Let AI call functions in your application.
  </Card>
</Cards>

---

## Providers

Import providers from subpaths for optimal tree-shaking:

```ts
import { openai } from '@yourgpt/llm-sdk/openai';
import { anthropic } from '@yourgpt/llm-sdk/anthropic';
import { google } from '@yourgpt/llm-sdk/google';
import { xai } from '@yourgpt/llm-sdk/xai';
```

Each provider function returns a model instance:

```ts
const gpt4 = openai('gpt-4o');
const claude = anthropic('claude-3-5-sonnet-20241022');
const gemini = google('gemini-2.0-flash');
const grok = xai('grok-3-fast-beta');
```

See [Providers](/docs/providers) for full configuration options.

---

## Streaming in API Routes

The most common pattern - create a streaming chat endpoint:

```ts title="app/api/chat/route.ts"
import { streamText } from '@yourgpt/llm-sdk';
import { openai } from '@yourgpt/llm-sdk/openai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: openai('gpt-4o'),
    system: 'You are a helpful assistant.',
    messages,
  });

  return result.toTextStreamResponse();
}
```

---

## With Tools

Add AI-callable functions to your application:

```ts
import { generateText, tool } from '@yourgpt/llm-sdk';
import { openai } from '@yourgpt/llm-sdk/openai';
import { z } from 'zod';

const result = await generateText({
  model: openai('gpt-4o'),
  prompt: 'What is the weather in Tokyo and Paris?',
  tools: {
    getWeather: tool({
      description: 'Get current weather for a city',
      parameters: z.object({
        city: z.string().describe('City name'),
      }),
      execute: async ({ city }) => {
        // Your weather API call here
        return { temperature: 22, condition: 'sunny' };
      },
    }),
  },
  maxSteps: 5, // Allow multiple tool calls
});

console.log(result.text);
// "The weather in Tokyo is 22Â°C and sunny. In Paris..."
```

---

## Key Concepts

| Concept | Description |
|---------|-------------|
| **Model** | Provider + model ID, e.g., `openai('gpt-4o')` |
| **Messages** | Conversation history with roles (user, assistant, system) |
| **Tools** | Functions the AI can call during generation |
| **maxSteps** | Maximum agentic iterations (tool call loops) |
| **Streaming** | Real-time text output via async iterables |

---

## Next Steps

<Cards>
  <Card title="generateText()" href="/docs/llm-sdk/generate-text">
    Full API reference for text generation
  </Card>
  <Card title="Providers" href="/docs/providers">
    Configure OpenAI, Anthropic, Google, and more
  </Card>
  <Card title="Copilot UI" href="/docs/chat">
    Build complete chat interfaces with React
  </Card>
</Cards>
