---
title: Ollama
description: Run models locally on your machine
---

import { Callout } from 'fumadocs-ui/components/callout';

<Callout type="warn">
**Coming Soon.** Ollama integration is under active development.
</Callout>

<ProviderHeader
  provider="ollama"
  name="Ollama"
  description="Run models locally - free & private"
/>

Run open-source LLMs locally. Free, private, no API keys needed.

---

## Get Started

Download Ollama from [ollama.com](https://ollama.com/)
