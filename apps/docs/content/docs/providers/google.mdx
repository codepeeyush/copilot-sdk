---
title: Google (Gemini)
description: Use Gemini 2.0, Gemini 1.5 Pro, and Flash models
---

import { Callout } from 'fumadocs-ui/components/callout';

<ProviderHeader
  provider="google"
  name="Google Generative AI"
  description="Gemini 2.0 Flash, Gemini 1.5 Pro"
/>

Google's Gemini models. Excellent for multimodal tasks with massive context windows.

---

## Setup

### 1. Get API Key

Get your API key from [Google AI Studio](https://aistudio.google.com/apikey)

### 2. Add Environment Variable

```bash title=".env.local"
GOOGLE_API_KEY=...
```

### 3. Usage

```ts
import { generateText } from '@yourgpt/llm-sdk';
import { google } from '@yourgpt/llm-sdk/google';

const result = await generateText({
  model: google('gemini-2.0-flash'),
  prompt: 'Explain machine learning.',
});

console.log(result.text);
```

### 4. Streaming (API Route)

```ts title="app/api/chat/route.ts"
import { streamText } from '@yourgpt/llm-sdk';
import { google } from '@yourgpt/llm-sdk/google';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: google('gemini-2.0-flash'),
    system: 'You are a helpful assistant.',
    messages,
  });

  return result.toTextStreamResponse();
}
```

---

## Available Models

```ts
// Gemini 2.0 (Latest)
google('gemini-2.0-flash')        // Fast and capable
google('gemini-2.0-flash-lite')   // Most efficient

// Gemini 1.5
google('gemini-1.5-pro')          // Best quality
google('gemini-1.5-flash')        // Fast and cheap
```

---

## Configuration Options

```ts
import { google } from '@yourgpt/llm-sdk/google';

// Custom API key
const model = google('gemini-2.0-flash', {
  apiKey: 'custom-api-key',
});

// With generation options
const result = await generateText({
  model: google('gemini-2.0-flash'),
  prompt: 'Hello',
  temperature: 0.7,        // 0-1
  maxTokens: 8192,         // Max response length
});
```

---

## Tool Calling

```ts
import { generateText, tool } from '@yourgpt/llm-sdk';
import { google } from '@yourgpt/llm-sdk/google';
import { z } from 'zod';

const result = await generateText({
  model: google('gemini-2.0-flash'),
  prompt: 'Search our knowledge base for AI topics',
  tools: {
    searchKnowledge: tool({
      description: 'Search internal knowledge base',
      parameters: z.object({
        query: z.string(),
        category: z.string().optional(),
      }),
      execute: async ({ query, category }) => {
        return await searchKnowledge(query, category);
      },
    }),
  },
  maxSteps: 5,
});
```

---

## Massive Context Window

Gemini supports 1M+ token context:

```ts
const result = await generateText({
  model: google('gemini-1.5-pro'),
  system: `Here is the entire codebase:

  ${entireCodebase}  // Can be 500K+ tokens!

  Help users understand and modify this code.`,
  prompt: userQuestion,
});
```

---

## Multimodal (Images, Video, Audio)

Gemini excels at multimodal understanding:

```ts
const result = await generateText({
  model: google('gemini-2.0-flash'),
  messages: [
    {
      role: 'user',
      content: [
        { type: 'text', text: "What's in this image?" },
        { type: 'image', image: imageBase64 },
      ],
    },
  ],
});
```

---

## With Copilot UI

Use with the Copilot React components:

```tsx title="app/providers.tsx"
'use client';

import { CopilotProvider } from '@yourgpt/copilot-sdk/react';

export function Providers({ children }: { children: React.ReactNode }) {
  return (
    <CopilotProvider runtimeUrl="/api/chat">
      {children}
    </CopilotProvider>
  );
}
```

---

## Pricing

| Model | Input | Output |
|-------|-------|--------|
| gemini-2.0-flash | Free tier available | See pricing |
| gemini-1.5-pro | $1.25/1M tokens | $5/1M tokens |
| gemini-1.5-flash | $0.075/1M tokens | $0.30/1M tokens |

*Very competitive pricing. Check [Google AI pricing](https://ai.google.dev/pricing) for current rates.*

---

## Next Steps

- [xAI](/docs/providers/xai) - Ultra-fast inference
- [generateText()](/docs/llm-sdk/generate-text) - Full API reference
- [tool()](/docs/llm-sdk/tools) - Define tools with Zod
