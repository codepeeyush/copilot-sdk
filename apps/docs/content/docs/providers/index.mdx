---
title: Providers Overview
description: Connect to any LLM provider
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';

Copilot SDK supports multiple LLM providers through `@yourgpt/llm-sdk`. **Switch providers without changing your frontend code.**

<Callout type="info">
All providers use the same API. Change one line in your backend to switch from OpenAI to Anthropic.
</Callout>

<ProviderCards />

---

## How It Works

Import providers from subpaths for optimal tree-shaking. Each provider returns a model instance that works with `generateText()` and `streamText()`.

### Backend Setup

```ts title="app/api/chat/route.ts"
import { streamText } from '@yourgpt/llm-sdk';
import { openai } from '@yourgpt/llm-sdk/openai';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = await streamText({
    model: openai('gpt-4o-mini'),
    system: 'You are a helpful assistant.',
    messages,
  });

  return result.toTextStreamResponse();
}
```

### Frontend Setup

```tsx title="app/providers.tsx"
'use client';

import { CopilotProvider } from '@yourgpt/copilot-sdk/react';

export function Providers({ children }: { children: React.ReactNode }) {
  return (
    <CopilotProvider runtimeUrl="/api/chat">
      {children}
    </CopilotProvider>
  );
}
```

---

## Switching Providers

Change the import and model - frontend stays the same:

```ts title="app/api/chat/route.ts"
import { streamText } from '@yourgpt/llm-sdk';

// OpenAI
import { openai } from '@yourgpt/llm-sdk/openai';
const model = openai('gpt-4o');

// Anthropic
import { anthropic } from '@yourgpt/llm-sdk/anthropic';
const model = anthropic('claude-3-5-sonnet-20241022');

// Google
import { google } from '@yourgpt/llm-sdk/google';
const model = google('gemini-2.0-flash');

// xAI
import { xai } from '@yourgpt/llm-sdk/xai';
const model = xai('grok-3-fast-beta');

// Use any model
const result = await streamText({
  model,
  messages,
});
```

<Callout type="info">
Your tools, UI, and all frontend code remain unchanged. The SDK normalizes responses across providers.
</Callout>

---

## Available Providers

| Provider | Import | Example |
|----------|--------|---------|
| OpenAI | `@yourgpt/llm-sdk/openai` | `openai('gpt-4o')` |
| Anthropic | `@yourgpt/llm-sdk/anthropic` | `anthropic('claude-3-5-sonnet-20241022')` |
| Google | `@yourgpt/llm-sdk/google` | `google('gemini-2.0-flash')` |
| xAI | `@yourgpt/llm-sdk/xai` | `xai('grok-3-fast-beta')` |

---

## Provider Comparison

| Provider | Speed | Quality | Cost | Best For |
|----------|-------|---------|------|----------|
| OpenAI | Fast | Excellent | $$ | General use |
| Anthropic | Medium | Excellent | $$ | Long context, safety |
| Google | Fast | Very Good | $ | Multimodal |
| xAI | Ultra Fast | Excellent | $ | Speed-critical apps |
