---
title: Providers Overview
description: Connect to any LLM provider
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';

Copilot SDK supports multiple LLM providers through `@yourgpt/llm-sdk`. **Switch providers without changing your frontend code.**

<Callout type="info">
All providers use the same API. Change one line in your backend to switch from OpenAI to Anthropic.
</Callout>

<ProviderCards />

---

## How It Works

Provider configuration is done on the **backend** using `@yourgpt/llm-sdk`. The frontend just connects to your API route.

### Backend Setup

```ts title="app/api/chat/route.ts"
import { createRuntime, createOpenAI } from '@yourgpt/llm-sdk';

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

const runtime = createRuntime({
  provider: openai,
  model: 'gpt-4o-mini',
  systemPrompt: 'You are a helpful assistant.',
});

export async function POST(request: Request) {
  return runtime.handleRequest(request);
}
```

### Frontend Setup

```tsx title="app/providers.tsx"
'use client';

import { CopilotProvider } from '@yourgpt/copilot-sdk/react';

export function Providers({ children }: { children: React.ReactNode }) {
  return (
    <CopilotProvider runtimeUrl="/api/chat">
      {children}
    </CopilotProvider>
  );
}
```

---

## Switching Providers

Change the provider factory on the backend - frontend stays the same:

```ts title="app/api/chat/route.ts"
import {
  createRuntime,
  createOpenAI,
  createAnthropic
} from '@yourgpt/llm-sdk';

// OpenAI
const openai = createOpenAI({ apiKey: process.env.OPENAI_API_KEY! });
const runtime = createRuntime({ provider: openai, model: 'gpt-4o' });

// Or Anthropic
const anthropic = createAnthropic({ apiKey: process.env.ANTHROPIC_API_KEY! });
const runtime = createRuntime({ provider: anthropic, model: 'claude-sonnet-4-20250514' });
```

<Callout type="info">
Your tools, UI, and all frontend code remain unchanged. The SDK normalizes responses across providers.
</Callout>

---

## Available Providers

| Provider | Status | Factory Function |
|----------|--------|------------------|
| OpenAI | Ready | `createOpenAI()` |
| Anthropic | Ready | `createAnthropic()` |
| Google | Coming Soon | `createGoogle()` |
| Groq | Coming Soon | `createGroq()` |
| Mistral | Coming Soon | - |
| Azure OpenAI | Coming Soon | `createAzure()` |
| Ollama | Coming Soon | `createOllama()` |

---

## Provider Comparison

| Provider | Speed | Quality | Cost | Best For |
|----------|-------|---------|------|----------|
| OpenAI | Fast | Excellent | $$ | General use |
| Anthropic | Medium | Excellent | $$ | Long context, safety |
| Google | Fast | Very Good | $ | Multimodal |
| Groq | Ultra Fast | Good | $ | Speed-critical apps |
| Ollama | Varies | Varies | Free | Local/private |
